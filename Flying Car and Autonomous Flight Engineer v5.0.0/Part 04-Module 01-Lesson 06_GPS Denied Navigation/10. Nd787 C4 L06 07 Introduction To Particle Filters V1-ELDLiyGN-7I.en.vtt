WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.640
We've assumed throughout the estimation module

00:00:02.640 --> 00:00:04.995
that all our noise distributions are Gaussian,

00:00:04.995 --> 00:00:08.085
and we've mostly assume that our models are linear,

00:00:08.085 --> 00:00:10.660
and when they weren't linear then the Taylor series or

00:00:10.660 --> 00:00:13.519
unscented transform were reasonable approximations.

00:00:13.519 --> 00:00:16.945
But, there are many ways things can become non-Gaussian.

00:00:16.945 --> 00:00:19.260
For example, our measurement model can be

00:00:19.260 --> 00:00:22.600
non-Gaussian or our state estimate might be non-Gaussian.

00:00:22.600 --> 00:00:26.020
We might believe we're either here or there,

00:00:26.019 --> 00:00:28.730
in which case we'd call that a multi-model belief.

00:00:28.730 --> 00:00:31.469
These situations show up especially often in

00:00:31.469 --> 00:00:34.494
a GPS to night navigation because a lot of the sensors that we use,

00:00:34.494 --> 00:00:36.839
especially ranging sensors like LIDAR,

00:00:36.840 --> 00:00:40.065
are really non-linear and really non-Gaussian.

00:00:40.064 --> 00:00:46.439
Why is that the case? Well, if a range sensor is pointing at a wall like this,

00:00:46.439 --> 00:00:48.689
the range will depend on the cosine of Theta,

00:00:48.689 --> 00:00:51.509
the bearing of the sensor which is clearly non-linear.

00:00:51.509 --> 00:00:53.320
But why is it non-Gaussian?

00:00:53.320 --> 00:00:55.380
For it just pointing at this wall and

00:00:55.380 --> 00:00:58.260
the distribution on the range measure really would be Gaussian.

00:00:58.259 --> 00:01:01.379
But imagine this wall has a corner like this,

00:01:01.380 --> 00:01:03.745
and the sensor is pointing at that corner.

00:01:03.744 --> 00:01:06.629
Now, a slight perturbation in the bearing will

00:01:06.629 --> 00:01:09.509
cause the sensor to go all the way out to some maximum value,

00:01:09.510 --> 00:01:13.530
missing the corner and that distribution between hitting the obstacle right there on

00:01:13.530 --> 00:01:15.724
the corner and getting a max range measurement

00:01:15.724 --> 00:01:18.375
from missing the corner, that's really non-Gaussian.

00:01:18.375 --> 00:01:21.120
This makes range sensors really hard to deal with in the

00:01:21.120 --> 00:01:24.620
Kalman filter setting. What about the state estimate?

00:01:24.620 --> 00:01:28.170
Well, if we don't have GPS and we're relying on maps and

00:01:28.170 --> 00:01:32.469
landmarks to estimate our location in some grid of city blocks for example,

00:01:32.469 --> 00:01:34.905
then the vehicle may not know whether its actually in

00:01:34.905 --> 00:01:40.310
this intersection or in that intersection since they might look very similar.

00:01:40.310 --> 00:01:43.810
You could represent that as a mixture of Gaussians

00:01:43.810 --> 00:01:47.225
where the vehicle knows it's in one of a couple of different locations,

00:01:47.224 --> 00:01:49.609
but doesn't know exactly which one.

00:01:49.609 --> 00:01:52.709
This is another example that's really hard to deal with in

00:01:52.709 --> 00:01:57.024
the conventional Kalman filter typesetting.

00:01:57.025 --> 00:02:01.109
Fortunately, there are methods of state estimation that

00:02:01.109 --> 00:02:05.474
are better suited to these highly non-linear and non-Gaussian situations.

00:02:05.474 --> 00:02:11.060
The approach we're going to discuss here is something called particle filter.

00:02:11.099 --> 00:02:15.340
The main idea behind particle filter is that instead of

00:02:15.340 --> 00:02:18.925
maintaining a single belief with an associated uncertainty,

00:02:18.925 --> 00:02:21.015
we're going to keep track of many,

00:02:21.014 --> 00:02:23.964
maybe hundreds or thousands of particles.

00:02:23.965 --> 00:02:28.175
Each of these particles will occupy some position in the state space.

00:02:28.175 --> 00:02:31.540
You can almost think of each particle as a simulated quadrotor.

00:02:31.539 --> 00:02:34.509
Then, we can mimic the prediction and measurement update

00:02:34.509 --> 00:02:37.384
steps that you saw with the common filter.

00:02:37.384 --> 00:02:40.750
With a particle filter, prediction involves using the controls commanded to

00:02:40.750 --> 00:02:43.060
the actual vehicle to advance each particle

00:02:43.060 --> 00:02:45.865
forward in time according to the appropriate dynamics.

00:02:45.865 --> 00:02:50.719
The measurement update in turn involves comparing the drone's real sensor measurements,

00:02:50.719 --> 00:02:53.900
so the measurements we'd expect each particle to see.

00:02:53.900 --> 00:02:57.530
When a real measurement is close to what we'd expect,

00:02:57.530 --> 00:03:00.675
that particle has its particle weight increased.

00:03:00.675 --> 00:03:03.070
When a measurement is different from what we'd expect,

00:03:03.069 --> 00:03:05.495
then that particle has its weight decreased.

00:03:05.495 --> 00:03:08.149
When we actually need a consistent state estimate,

00:03:08.149 --> 00:03:11.164
we can use a weighted average of all the particle states.

00:03:11.164 --> 00:03:14.715
So, this is a very high level explanation of a particle filter.

00:03:14.715 --> 00:03:17.479
Let's dive into how this all actually works.

