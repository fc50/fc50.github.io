WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.229
One thing to note is that any sensor on a flying car

00:00:03.229 --> 00:00:06.839
or any autonomous vehicle is going to be a digital device,

00:00:06.839 --> 00:00:09.785
and can only return a discrete set of range values.

00:00:09.785 --> 00:00:13.769
We could therefore collect a big dataset of laser range measurements

00:00:13.769 --> 00:00:18.320
and simply count how many times we get each possible range value.

00:00:18.320 --> 00:00:22.594
Since the probability depends on the range to the actual object being sensed,

00:00:22.594 --> 00:00:24.899
we would need to put the sensor at

00:00:24.899 --> 00:00:29.219
all possible distances to obstacles and then collect our data.

00:00:29.219 --> 00:00:32.789
But we could do that and we could count up

00:00:32.789 --> 00:00:36.140
how many times we get each range value for each distance.

00:00:36.140 --> 00:00:39.480
This would give us a nice lookup table which would let us

00:00:39.479 --> 00:00:43.194
convert an expected distance x sub t minus Lambda,

00:00:43.195 --> 00:00:46.125
into a measurement probability distribution.

00:00:46.125 --> 00:00:50.909
Now, how do we find Lambda the position of the nearest obstacle along

00:00:50.909 --> 00:00:55.974
the bearing in order to compute the expected distance x sub t minus Lambda?

00:00:55.975 --> 00:00:59.280
We've actually done this before in a grid map.

00:00:59.280 --> 00:01:02.755
Remember the Bresenham ray tracing algorithm from planning?

00:01:02.755 --> 00:01:05.310
We can use that exact same algorithm again here.

00:01:05.310 --> 00:01:09.900
What we do is we put the vehicle on the map wherever a sample is,

00:01:09.900 --> 00:01:12.260
and along the bearing that the sensor is measuring,

00:01:12.260 --> 00:01:17.564
we basically walk through the grid cells until we actually get to an obstacle cell.

00:01:17.564 --> 00:01:24.579
Of course, we are tracing between two points but from the sensor in a given direction.

00:01:24.579 --> 00:01:27.450
We can get the Bresenham effect of a second point by

00:01:27.450 --> 00:01:30.060
finding a point P2 at the edge of the map,

00:01:30.060 --> 00:01:33.810
along the bearing of the sensor and then ray tracing from x sub t to

00:01:33.810 --> 00:01:37.990
P2 and stopping when we hit our first obstacle cell in the map.

00:01:37.989 --> 00:01:40.530
If we're working with a planar lidar that

00:01:40.530 --> 00:01:43.605
spins and makes range measurements once every degree,

00:01:43.605 --> 00:01:48.125
then that means that z sub t will be a 360 dimensional vector.

00:01:48.125 --> 00:01:50.659
We can probably assume independent measurements,

00:01:50.659 --> 00:01:53.789
which means that P of z sub t given x sub t is

00:01:53.790 --> 00:01:57.109
just the product of the 360 individual measurements.

00:01:57.109 --> 00:02:02.234
That means the weight of each sample will be the product of all these likelihoods.

00:02:02.234 --> 00:02:05.668
Since we're doing this for every measurement,

00:02:05.668 --> 00:02:07.859
for every sample x sub t,

00:02:07.859 --> 00:02:10.724
i the computation can really add up.

00:02:10.724 --> 00:02:15.530
That's why we like efficient ray tracing algorithms like the Bresenham algorithm.

